import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.linear_model import LinearRegression

st.set_page_config(layout="wide")

st.title("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

uploaded_file = st.file_uploader("ğŸ“ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù CSV Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ù†Ù…Ø§Ø°Ø¬", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­")

    st.subheader("ğŸ‘ï¸â€ğŸ—¨ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø£ÙˆÙ„ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    st.write(df.head())

    df['Publication date'] = pd.to_datetime(df['Publication date'], errors='coerce')
    df['Year'] = df['Publication date'].dt.year

    st.subheader("ğŸ“ˆ Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ù„ÙƒÙ„ Ø³Ù†Ø©")
    papers_per_year = df['Year'].value_counts().sort_index()
    st.bar_chart(papers_per_year)

    st.subheader("ğŸ“Œ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§")
    if 'Category' in df.columns:
        st.bar_chart(df['Category'].value_counts())

    st.subheader("ğŸ“‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø¨Ù…Ø±ÙˆØ± Ø§Ù„Ø³Ù†ÙˆØ§Øª")
    df_yearly = df.groupby('Year').size().reset_index(name='Count').dropna()
    X = df_yearly[['Year']]
    y = df_yearly['Count']
    model = LinearRegression()
    model.fit(X, y)
    y_pred = model.predict(X)

    fig, ax = plt.subplots()
    ax.scatter(X, y, label='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©')
    ax.plot(X, y_pred, color='red', label='Ø®Ø· Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±')
    ax.set_xlabel("Ø§Ù„Ø³Ù†Ø©")
    ax.set_ylabel("Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚")
    ax.set_title("ğŸ“‰ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ")
    ax.legend()
    st.pyplot(fig)

    st.subheader("ğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù†Ù‚ÙˆØ¯ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… K-Means")
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    if numeric_features:
        X_cluster = df[numeric_features].dropna()

if not X_cluster.empty:
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_cluster)
    kmeans = KMeans(n_clusters=3, random_state=0)
    clusters = kmeans.fit_predict(X_scaled)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)
    fig2, ax2 = plt.subplots()
    scatter = ax2.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis')
    ax2.set_title("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¬Ù…ÙŠØ¹")
    st.pyplot(fig2)
else:
    st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø¯Ø¯ÙŠØ© ÙƒØ§ÙÙŠØ© Ø¨Ø¯ÙˆÙ† Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¬Ù…ÙŠØ¹.")


    st.subheader("ğŸ§  Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest")
    df_model = df.dropna()
    target_column = st.selectbox("ğŸ¯ Ø§Ø®ØªØ§Ø±ÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ù„Ù„ØªØµÙ†ÙŠÙ", df_model.columns)
    feature_columns = st.multiselect("ğŸ§© Ø§Ø®ØªØ§Ø±ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙƒÙ…ÙŠØ²Ø§Øª", df_model.columns.drop(target_column))

    if feature_columns:
        X = df_model[feature_columns]
        y = df_model[target_column]

        numeric_features = X.select_dtypes(include=['int64', 'float64']).columns
        categorical_features = X.select_dtypes(include=['object', 'bool']).columns

        numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())])

        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)])

        clf = Pipeline(steps=[('preprocessor', preprocessor),
                              ('classifier', RandomForestClassifier())])

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)

        st.write("ğŸ” Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:", accuracy_score(y_test, y_pred))
        st.write("ğŸ¯ Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹:", recall_score(y_test, y_pred, average='weighted', zero_division=0))
        st.write("ğŸ¯ Ø§Ù„Ø¯Ù‚Ø©:", precision_score(y_test, y_pred, average='weighted', zero_division=0))
