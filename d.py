import streamlit as st
import pandas as pd
import io
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier
import numpy as np

# Set up Streamlit UI
st.set_page_config(layout="wide", page_title="NABLS-AI Dashboard")
st.title('NABLS-AI: ุชุญููู ุงูุงุชุฌุงูุงุช ูู ุฃุจุญุงุซ ุงูุฐูุงุก ุงูุงุตุทูุงุนู')
st.info('NABLS-AI: ุฃุฏุงุฉ ูุชุญููู ุงูุจูุงูุงุช ูุงุณุชูุดุงู ุงูุงุชุฌุงูุงุช ูู ุฃุจุญุงุซ ุงูุฐูุงุก ุงูุงุตุทูุงุนู.')

# --- ุชุญููู ุงูุจูุงูุงุช ูู ูุณุงุฑ ุซุงุจุช ---
st.header("ุจูุงูุงุช ุงููุตุฏุฑ ๐")

# === ูุงู: ุงูุฑุฌุงุก ุชุบููุฑ ูุฐุง ุงููุณุงุฑ ุฅูู ุงููุณุงุฑ ุงููุนูู ููููู ===
# ุงุณุชุฎุฏู ุงููุณุงุฑ ุจูุธุงู ุงูุดุฑุทุฉ ุงููุงุฆูุฉ ุงูุฃูุงููุฉ / ุฃู ุฃุถู 'r' ูุจู ุงููุณุงุฑ
file_path = 'C:/Users/BAB AL SAFA/Desktop/nablsai/ai_models.csv'
# ูุซุงู ุนูู ูุณุงุฑ ูุณุจู ุฅุฐุง ูุงู ุงูููู ูู ููุณ ูุฌูุฏ ุชุทุจูู Streamlit:
# file_path = 'ai_models.csv'

try:
    df = pd.read_csv(file_path)
    st.success(f"ุชู ุชุญููู ุงูููู ูู: {file_path}")
    st.subheader("ูุนุงููุฉ ุงูุจูุงูุงุช ุงูุฃูููุฉ")
    st.dataframe(df.head())
except FileNotFoundError:
    st.error(f"ุฎุทุฃ: ุงูููู '{file_path}' ุบูุฑ ููุฌูุฏ. ุงูุฑุฌุงุก ุงูุชุฃูุฏ ูู ุงููุณุงุฑ ุงูุตุญูุญ.")
    st.stop() # ุฅููุงู ุงูุชูููุฐ ุฅุฐุง ูู ูุชู ุงูุนุซูุฑ ุนูู ุงูููู

# --- ูุญุฑุฑ ุงูููุฏ ุงููุงุจู ููุชุนุฏูู ---
st.header("ุชุนุฏูู ุงูููุฏ ูุชุญููู ุงูุจูุงูุงุช โ๏ธ")
st.markdown("""
    ููููู ุชุนุฏูู ุงูููุฏ ูู ุงูุฃุณูู ูุชูููุฐ ุชุญูููุงุชู ุงูุฎุงุตุฉ.
    **ููุงุญุธุงุช ูุงูุฉ:**
    * **ูุง ุชูู ุจุฅุนุงุฏุฉ ุชุญููู `df` ูู ูููุงุช CSV ุฃุฎุฑู ุฏุงุฎู ุงูููุฏ ูุง ูู ููู ุฐูู ุถุฑูุฑููุง ููุบุงูุฉ.** ุงููุชุบูุฑ `df` ูุญุชูู ุจุงููุนู ุนูู ุงูุจูุงูุงุช ุงููุญููุฉ.
    * **ุงุณุชุฎุฏู `st.write()` ูููุตูุตุ `st.dataframe()` ููุฌุฏุงููุ ู `st.pyplot()` ููุฑุณูู ุงูุจูุงููุฉ.**
    * **ุชู ุชุนุฏูู ุฌููุน ูุณุงุฑุงุช `df.to_csv` ุฏุงุฎู ุงูููุฏ ุฅูู ูุณุงุฑุงุช ุฎุงู (ุจุงุณุชุฎุฏุงู `r''`) ูุถูุงู ุงูุชูุงูู.**
""")

# Default code for the user to edit
cody = '''
# ุจุฏุงูุฉ ุงูุชุญููู: By Noora, Sedrah, Basmaleh

# ุชูุธูู ุงูุจูุงูุงุช ููุนุงูุฌุชูุง - (ุจูุงุณุทุฉ Noora)
# df ูู DataFrame ุงูุฐู ุชู ุชุญูููู ุจุงููุนู ูู ุจุฏุงูุฉ ุงูุชุทุจูู.
# ูุง ุชูู ุจุฅุนุงุฏุฉ ุชุญููู ุงูุจูุงูุงุช ููุง ุฅูุง ุฅุฐุง ููุช ุชุญุชุงุฌ ุฅูู ููู ุขุฎุฑ.
# df = pd.read_csv(r'C:/Users/BAB AL SAFA/Desktop/nablsai/ai_models.csv')

if 'Confidence' in df.columns:
    df = df.dropna(subset=["Confidence"])
    df['Confidence'] = df['Confidence'].str.strip().str.lower()
    df = df[df['Confidence'] != 'unknown']

    confidence_count = df["Confidence"].count()
    equ = confidence_count * 0.85
    columns_to_drop = []
    for column_name in df.columns:
        current_column_non_null_count = df[column_name].count()
        if current_column_non_null_count < equ:
            columns_to_drop.append(column_name)

    st.write(f"ุงูููู ุงููุฑูุฏุฉ ูู Confidence: {df['Confidence'].unique()}")
    if columns_to_drop:
        df.drop(columns=columns_to_drop, axis=1, inplace=True)
        st.write(f"ุชู ุฅุณูุงุท ุงูุฃุนูุฏุฉ: {columns_to_drop}")
    else:
        st.write("ูู ูุชู ุฅุณูุงุท ุฃู ุฃุนูุฏุฉ ุจูุงุกู ุนูู ุงูุญุฏ ุงูุฃุฏูู.")

    for column in df.columns:
        if df[column].isnull().sum() > 0:
            mode_value = df[column].mode()[0]
            df[column].fillna(mode_value, inplace=True)
else:
    st.warning("ุนููุฏ 'Confidence' ุบูุฑ ููุฌูุฏ. ุชู ุชุฎุทู ูุนุงูุฌุฉ ูุฐุง ุงูุนููุฏ.")

# ุญูุธ ุงูุชุบููุฑุงุช ุฅูู ููู ุฌุฏูุฏ (ุงุฎุชูุงุฑูุ ููุฏ ูุง ูููู ูุนุงูุงู ูู ุจูุฆุงุช ุงููุดุฑ ุงูุณุญุงุจูุฉ)
df.to_csv(r'C:/Users/BAB AL SAFA/Desktop/nablsai/updated_file3.csv', index=False)

# ุชุญููู K-Nearest Neighbors (KNN) - (ุจูุงุณุทุฉ Noora)
# df ูู DataFrame ุงูุฐู ุชู ุชุญูููู ููุนุงูุฌุชู ุจุงููุนู.
# ูุง ุชูู ุจุฅุนุงุฏุฉ ุชุญููู ุงูุจูุงูุงุช ููุง.
# df = pd.read_csv(r'C:/Users/BAB AL SAFA/Desktop/nablsai/updated_file3.csv')

if 'Confidence' in df.columns:
    X = df.drop("Confidence", axis=1)
    y = df["Confidence"]

    for col in X.columns:
        if X[col].dtype == 'object':
            X[col] = X[col].astype(str)

    X = pd.get_dummies(X)

    le = LabelEncoder()
    y = le.fit_transform(y)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    knn = KNeighborsClassifier(n_neighbors=2)
    knn.fit(X_train, y_train)

    y_pred = knn.predict(X_test)

    st.subheader("ูุชุงุฆุฌ ูููุฐุฌ K-Nearest Neighbors (KNN)")
    st.write(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
    st.write(f"Precision: {precision_score(y_test, y_pred, average='weighted', zero_division=0):.2f}")
    st.write(f"Recall: {recall_score(y_test, y_pred, average='weighted', zero_division=0):.2f}")
    st.write(f"F1 Score: {f1_score(y_test, y_pred, average='weighted', zero_division=0):.2f}")
    st.write("Confusion Matrix:")
    st.code(confusion_matrix(y_test, y_pred))
    st.write("Classification Report:")
    st.text(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))

    error_rate = []
    max_k = min(40, len(X_train) // 2)
    if max_k < 1:
        st.warning("ุจูุงูุงุช ุงูุชุฏุฑูุจ ููููุฉ ุฌุฏูุง ูุจูุงุก ูุฎุทุท ูุนุฏู ุงูุฎุทุฃ ูู KNN.")
    else:
        for i in range(1, max_k + 1):
            knn = KNeighborsClassifier(n_neighbors=i)
            knn.fit(X_train, y_train)
            pred_i = knn.predict(X_test)
            error_rate.append(np.mean(pred_i != y_test))

        fig_knn_error, ax_knn_error = plt.subplots(figsize=(10,6))
        ax_knn_error.plot(range(1, max_k + 1), error_rate, color='blue', linestyle='dashed', marker='o',
                        markerfacecolor='red', markersize=10)
        ax_knn_error.set_title('ูุนุฏู ุงูุฎุทุฃ ููุงุจู ูููุฉ K')
        ax_knn_error.set_xlabel('ูููุฉ K')
        ax_knn_error.set_ylabel('ูุนุฏู ุงูุฎุทุฃ')
        ax_knn_error.grid(True)
        st.pyplot(fig_knn_error)
        plt.close(fig_knn_error)
else:
    st.warning("ุนููุฏ 'Confidence' ุบูุฑ ููุฌูุฏุ ูุง ูููู ุฅุฌุฑุงุก ุชุญููู KNN.")


# ุชูุธูู ุงูุจูุงูุงุช ูุฅุนุฏุงุฏูุง (ุจูุงุณุทุฉ Sedrah)
# df ูู DataFrame ุงูุฐู ุชู ุชุญูููู ููุนุงูุฌุชู ุจุงููุนู.
# ูุง ุชูู ุจุฅุนุงุฏุฉ ุชุญููู ุงูุจูุงูุงุช ููุง.
# df = pd.read_csv(r'C:/Users/BAB AL SAFA/Desktop/nablsai/ai_models.csv')

def classify_trend(model_name):
    if pd.isna(model_name): return 'Other'
    model_name = str(model_name)
    if 'AFM-on-device' in model_name:
        return 'On-Device AI,Closed Source,Efficiency'
    elif 'AFM-server' in model_name:
        return 'Large-Scale,Closed Source,AI Regulation'
    elif 'AlphaProteo' in model_name:
        return 'AI for Science,Closed Source'
    elif 'Amazon Nova Pro' in model_name:
        return 'Multimodal AI,Closed Source,Large-Scale'
    elif 'Cambrian' in model_name:
        return 'Multimodal AI,Open-Source AI,Domain-Specific'
    elif 'CHAI' in model_name:
        return 'AI for Science,Open-Source AI'
    elif 'Claude' in model_name:
        return 'Reasoning-Mathematics,Closed Source,AI Regulation'
    elif 'Computer-Using Agent ' in model_name:
        return 'Robotics AI,Closed Source,Multimodal AI'
    elif 'DeepL' in model_name:
        return 'Domain-Specific,Closed Source'
    elif 'DeepSeek-R1' in model_name:
        return 'Reasoning-Mathematics,Open-Source AI'
    elif 'DeepSeek-V2.5' in model_name:
        return 'Domain-Specific,Open-Source AI'
    elif 'DeepSeek-V3' in model_name:
        return 'Large-Scale,Open-Source AI'
    elif 'Doubao' in model_name:
        return 'Large-Scale,Closed Source'
    elif 'ERNIE' in model_name:
        return 'Multimodal AI,Closed Source'
    elif 'ESM' in model_name:
        return 'AI for Science,Open-Source AI'
    elif 'EXAONE' in model_name:
        return 'Reasoning-Mathematics,Open-Source AI'
    elif 'Fugatto' in model_name:
        return 'AI Generation,Open-Source AI'
    elif 'Gemin' in model_name:
        return 'Multimodal AI,Closed Source'
    elif 'GLM' in model_name:
        return 'Large-Scale,Closed Source'
    elif 'GPT-4.5' in model_name:
        return 'Large-Scale,Multimodal AI,Closed Source'
    elif 'GPT-4o' in model_name:
        return 'Multimodal AI,Closed Source,Efficiency'
    elif 'GR' in model_name:
        return 'Robotics AI,Open-Source AI'
    elif 'Hairuo' in model_name:
        return 'Domain-Specific'
    elif 'Hunyuan' in model_name:
        return 'Large-Scale,Open-Source AI,Multimodal AI'
    elif 'Infinity' in model_name:
        return 'AI Generation,Open-Source AI'
    elif ('INTELLECT' in model_name) or ('k0' in model_name):
        return 'Reasoning-Mathematics,Closed Source'
    elif 'LLaVA-OV-72B' in model_name:
        return 'Multimodal AI,Open-Source AI'
    elif 'Llama 3' in model_name:
        return 'Large-Scale,Open-Source AI,Multimodal AI'
    elif 'Llama 4' in model_name:
        return 'Ultra-Large-Scale,Multimodal AI,Closed Source'
    elif 'Mathstral' in model_name:
        return 'Reasoning-Mathematics,Open-Source AI'
    elif 'Mercury' in model_name:
        return 'Efficiency,Closed Source'
    elif 'Mistral' in model_name:
        return 'Large-Scale,Domain-Specific'
    elif ('Movie' in model_name) or ('Gen' in model_name):
        return 'AI Generation'
    elif 'Nemotron' in model_name:
        return 'Large-Scale,Open-Source AI'
    elif 'NVLM' in model_name:
        return 'Multimodal AI,Open-Source AI'
    elif 'Octo' in model_name:
        return 'Robotics AI,Open-Source AI'
    elif ('o1' in model_name) or ('o3' in model_name):
        return 'Reasoning-Mathematics,Efficiency'
    elif 'Open' in model_name:
        return 'Robotics AI,Open-Source AI'
    elif 'Pangu' in model_name:
        return 'Large-Scale'
    elif 'Palmyra' in model_name:
        return 'Domain-Specific'
    elif 'Pixtral' in model_name:
        return 'Multimodal AI,Open-Source AI'
    elif 'Qwen' in model_name:
        return 'Large-Scale,Open-Source AI'
    elif 'QwQ' in model_name:
        return 'Reasoning-Mathematics,Open-Source AI'
    elif 'Table' in model_name:
        return 'Robotics AI'
    elif ('Veo' in model_name) or ('Wan' in model_name):
        return 'AI Generation'
    elif 'Yi' in model_name:
        return 'Large-Scale,Efficiency'
    else:
        return 'Other'

if 'Model' in df.columns:
    df['AI_Trend'] = df['Model'].apply(classify_trend)
    df['AI_Trend'] = df['AI_Trend'].str.split(',')
    df = df.explode('AI_Trend')
    df['AI_Trend'] = df['AI_Trend'].str.strip()
    st.write(f"ุงูููู ุงููุฑูุฏุฉ ูู AI_Trend ุจุนุฏ ุงูุชุตููู ุงูุฃููู: {df['AI_Trend'].unique()}")
else:
    st.warning("ุนููุฏ 'Model' ุบูุฑ ููุฌูุฏ. ูู ูุชู ุชุตููู ุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู.")
    df['AI_Trend'] = 'Other'

if 'Publication date' in df.columns:
    df['Publication date'] = pd.to_datetime(df['Publication date'], errors='coerce')
    df['Year'] = df['Publication date'].dt.year
else:
    st.warning("ุนููุฏ 'Publication date' ุบูุฑ ููุฌูุฏ. ูู ูุชู ุญุณุงุจ ุงูุณูุฉ.")
    df['Year'] = 0

# ุญูุธ ุงูุชุบููุฑุงุช ุฅูู ููู ุฌุฏูุฏ (ุงุฎุชูุงุฑู)
df.to_csv(r'C:/Users/BAB AL SAFA/Desktop/nablsai/updated_file.csv', index=False)

trend_keywords = {
    'AI Generation': ['generate', 'generative', 'GAN', 'diffusion', 'image-to-image', 'synthesis'],
    'Efficiency': ['efficient', 'efficiency', 'dropout', 'compress', 'optimize', 'low-resource', 'reduce'],
    'Multimodal AI': ['multimodal', 'vision-language', 'text and image', 'audio and text'],
    'Robotics AI': ['robot', 'embodied', 'navigation', 'control', 'manipulation'],
    'Reasoning-Mathematics': ['math', 'reasoning', 'proof', 'solve equation'],
    'AI for Science': ['biology', 'chemistry', 'protein', 'scientific', 'molecule'],
    'Closed Source': ['not released', 'private', 'not available'],
    'Open-Source AI': ['open-source', 'released', 'public', 'github'],
    'Large-Scale': ['large dataset', 'scale', 'GPT', 'BERT', 'Transformer'],
    'Ultra-Large-Scale': ['100B', 'trillion', 'huge model', 'massive'],
    'On-Device AI': ['on-device', 'edge', 'mobile', 'low-power'],
    'AI Regulation': ['policy', 'ethics', 'governance', 'regulation', 'safety'],
    'Domain-Specific': ['medical', 'legal', 'finance', 'healthcare', 'education'],
}

def classify_ai_trend_reclassify(text):
    if pd.isna(text):
        return "Other"
    text = str(text).lower()
    for trend, keywords in trend_keywords.items():
        if any(keyword in text for keyword in keywords):
            return trend
    return "Other"

if 'AI_Trend' in df.columns and 'Abstract' in df.columns and 'Model' in df.columns:
    mask_other = df['AI_Trend'] == "Other"
    df.loc[mask_other, 'AI_Trend_Reclassified'] = (
        df.loc[mask_other, ['Abstract', 'Model']]
        .fillna('')
        .agg(' '.join, axis=1)
        .apply(classify_ai_trend_reclassify)
    )

    df['AI_Trend'] = df.apply(
        lambda row: row['AI_Trend_Reclassified'] if row['AI_Trend'] == "Other" and row['AI_Trend_Reclassified'] != "Other"
        else row['AI_Trend'],
        axis=1
    )
    df.drop(columns=['AI_Trend_Reclassified'], inplace=True, errors='ignore')
else:
    st.warning("ุฃุนูุฏุฉ ูุทููุจุฉ ูุชุตููู ุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู (AI_Trend, Abstract, Model) ููููุฏุฉ.")

# ุญูุธ ุงูุชุบููุฑุงุช ุฅูู ููู ุฌุฏูุฏ (ุงุฎุชูุงุฑู)
df.to_csv(r'C:/Users/BAB AL SAFA/Desktop/nablsai/updated_file.csv', index=False)


# ุชุญููู ุงูุงุชุฌุงูุงุช ุงูุณูููุฉ (ุจูุงุณุทุฉ Sedrah)
df = df[df['AI_Trend'] != 'Other']
if not df.empty and 'Year' in df.columns and 'AI_Trend' in df.columns:
    trend_by_year = df.groupby(['Year', 'AI_Trend']).size().reset_index(name='Model_Count')
    st.subheader("ุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุญุณุจ ุงูุณูุฉ")
    st.dataframe(trend_by_year.head())
else:
    st.warning("DataFrame ูุงุฑุบ ุฃู ุฃุนูุฏุฉ 'Year'/'AI_Trend' ููููุฏุฉ ุจุนุฏ ุงูุชุตููุฉ. ูุง ูููู ุญุณุงุจ ุงูุงุชุฌุงูุงุช ุงูุณูููุฉ.")
    trend_by_year = pd.DataFrame(columns=['Year', 'AI_Trend', 'Model_Count'])


# ุชุตูุฑ ุงูุงุชุฌุงูุงุช (ุจูุงุณุทุฉ Noora)
if 'AI_Trend' in df.columns and not df.empty and not trend_by_year.empty:
    AI_Trends_Frequency_df= df['AI_Trend'].value_counts().reset_index()
    AI_Trends_Frequency_df.columns = ['AI_Trend', 'Frequency']
    st.subheader("ุชูุฑุงุฑ ูู ุงุชุฌุงู ูู ุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู")
    st.dataframe(AI_Trends_Frequency_df)

    top_5_trends = AI_Trends_Frequency_df.nlargest(5, columns='Frequency')['AI_Trend'].tolist()
    filtered_top_5 = trend_by_year[trend_by_year['AI_Trend'].isin(top_5_trends)]

    if not filtered_top_5.empty:
        sns.set(style="whitegrid")
        fig_top5, ax_top5 = plt.subplots(figsize=(14, 7))
        sns.lineplot(data=filtered_top_5, x='Year', y='Model_Count', hue='AI_Trend', marker='o', ax=ax_top5)
        ax_top5.set_title('ุชุทูุฑ ุฃูู 5 ุงุชุฌุงูุงุช ููุฐูุงุก ุงูุงุตุทูุงุนู ุนุจุฑ ุงูุณููุงุช')
        ax_top5.set_xlabel('ุงูุณูุฉ')
        ax_top5.set_ylabel('ุนุฏุฏ ุงูููุงุฐุฌ')
        ax_top5.tick_params(axis='x', rotation=45)
        ax_top5.legend(title='ุงุชุฌุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู')
        plt.tight_layout()
        st.pyplot(fig_top5)
        plt.close(fig_top5)
    else:
        st.warning("ูุง ุชูุฌุฏ ุจูุงูุงุช ูุฑุณู ุฃูู 5 ุงุชุฌุงูุงุช ููุฐูุงุก ุงูุงุตุทูุงุนู ุจุนุฏ ุงูุชุตููุฉ.")
else:
    st.warning("ูุง ูููู ุญุณุงุจ ุชูุฑุงุฑ ุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนูุ ุงูุนููุฏ 'AI_Trend' ููููุฏ ุฃู DataFrame ูุงุฑุบ.")


# ุชุญููู ุงุชุฌุงูุงุช ุงููุฌุงู (ุจูุงุณุทุฉ Noora)
st.subheader("ุชุญููู ุงุชุฌุงูุงุช ุงููุฌุงู")
if 'Domain' in df.columns and not df.empty:
    df_clean = df.dropna(subset=['Domain'])
    df_exploded = df_clean.assign(Domain=df_clean['Domain'].str.split(',')).explode('Domain')
    df_exploded['Domain'] = df_exploded['Domain'].str.strip()

    if 'Year' in df_exploded.columns:
        domain_trends = df_exploded.groupby(['Year', 'Domain']).size().unstack(fill_value=0)
        st.write("ุงุชุฌุงูุงุช ุงููุฌุงู (ุงูุฐูู):")
        st.dataframe(domain_trends.tail())
    else:
        st.warning("ุนููุฏ 'Year' ููููุฏ ูู DataFrame ุงููุฌุงู. ูุง ูููู ุญุณุงุจ ุงุชุฌุงูุงุช ุงููุฌุงู ุญุณุจ ุงูุณูุฉ.")
        domain_trends = pd.DataFrame()
else:
    st.warning("ุนููุฏ 'Domain' ููููุฏ ุฃู DataFrame ูุงุฑุบ. ูุง ูููู ุฅุฌุฑุงุก ุชุญููู ุงุชุฌุงูุงุช ุงููุฌุงู.")
    domain_trends = pd.DataFrame()


# ุชุตูุฑ ุงุชุฌุงูุงุช ุงููุฌุงู (ุจูุงุณุทุฉ Noora)
st.subheader("ุฑุณูู ุจูุงููุฉ ูุงุชุฌุงูุงุช ุงููุฌุงู")
if not domain_trends.empty:
    sns.set(style="whitegrid")
    fig_top_domains, ax_top_domains = plt.subplots(figsize=(14, 6))
    top_domains = domain_trends.sum().sort_values(ascending=False).head(5).index
    if not top_domains.empty:
        domain_trends[top_domains].plot(marker='o', linewidth=1, ax=ax_top_domains)
        ax_top_domains.set_title("ุงุชุฌุงูุงุช ุฃูู 5 ูุฌุงูุงุช ุดุนุจูุฉ (2021โ2025)")
        ax_top_domains.set_xlabel("ุงูุณูุฉ")
        ax_top_domains.set_ylabel("ุนุฏุฏ ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู")
        ax_top_domains.legend(title="ุนุฏุฏ ุงูููุงุฐุฌ")
        plt.tight_layout()
        st.pyplot(fig_top_domains)
        plt.close(fig_top_domains)
    else:
        st.warning("ูู ูุชู ุงูุนุซูุฑ ุนูู ูุฌุงูุงุช ุนููุง ููุฑุณู ุงูุจูุงูู.")

    fig_all_domains, ax_all_domains = plt.subplots(figsize=(16, 8))
    domain_trends.plot(marker='.', linewidth=1, alpha=0.7, ax=ax_all_domains, legend=False)
    ax_all_domains.set_title("ุงุชุฌุงูุงุช ูุฌุงูุงุช ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู (2021โ2025)")
    ax_all_domains.set_xlabel("ุงูุณูุฉ")
    ax_all_domains.set_ylabel("ุนุฏุฏ ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู")
    plt.tight_layout()
    st.pyplot(fig_all_domains)
    plt.close(fig_all_domains)
else:
    st.warning("ูุง ุชูุฌุฏ ุจูุงูุงุช ูุงุชุฌุงูุงุช ุงููุฌุงู ูุชุตูุฑูุง.")


# ุชุทูุฑ ุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุฑุฏูุฉ (ุจูุงุณุทุฉ Sedrah)
st.subheader("ุชุทูุฑ ุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุฑุฏูุฉ")
if 'AI_Trend' in df.columns and not df.empty and 'trend_by_year' in locals() and not trend_by_year.empty:
    all_trends = df['AI_Trend'].unique()
    filtered = trend_by_year[trend_by_year['AI_Trend'].isin(all_trends)]

    for trend in all_trends:
        fig_single_trend, ax_single_trend = plt.subplots(figsize=(10, 5))
        data = filtered[filtered['AI_Trend'] == trend]
        if not data.empty:
            sns.lineplot(data=data, x='Year', y='Model_Count', marker='o', ax=ax_single_trend)
            ax_single_trend.set_title(f'ุชุทูุฑ {trend} ุนุจุฑ ุงูุณููุงุช')
            ax_single_trend.set_ylabel(trend)
            ax_single_trend.tick_params(axis='x', rotation=45)
            plt.tight_layout()
            st.pyplot(fig_single_trend)
            plt.close(fig_single_trend)
        else:
            st.write(f"ูุง ุชูุฌุฏ ุจูุงูุงุช ููุฑุณู ุงูุจูุงูู ููุงุชุฌุงู: {trend}")
else:
    st.warning("ูุง ูููู ุนุฑุถ ุชุทูุฑ ุงูุงุชุฌุงูุงุช ุงููุฑุฏูุฉ. ุจูุงูุงุช ุบูุฑ ูุงููุฉ ุฃู ุฃุนูุฏุฉ ููููุฏุฉ.")


# ูููุฐุฌ ุงูุงูุญุฏุงุฑ ููุชูุจุค ุจุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ุนุงู 2026 (ุจูุงุณุทุฉ Noora)
st.subheader("ูููุฐุฌ ุงูุงูุญุฏุงุฑ ููุชูุจุค ุจุงุชุฌุงูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ุนุงู 2026")

if 'top_5_trends' in locals() and top_5_trends and 'trend_by_year' in locals() and not trend_by_year.empty:
    st.write(f"ุฃูู 5 ุงุชุฌุงูุงุช ููุฐูุงุก ุงูุงุตุทูุงุนู ุชู ุชุญุฏูุฏูุง ููุชูุจุค: {top_5_trends}")

    filtered_trends_2021_2025 = trend_by_year[
        (trend_by_year['AI_Trend'].isin(top_5_trends)) &
        (trend_by_year['Year'] >= 2021) &
        (trend_by_year['Year'] <= 2025)
    ].copy()

    st.write("ุจูุงูุงุช ุงูุงุชุฌุงูุงุช ุงููุตูุงุฉ (2021-2025) ูุฃูู 5 ุงุชุฌุงูุงุช:")
    st.dataframe(filtered_trends_2021_2025)

    trend_models = {}
    trend_predictions_2026 = {}

    for trend in top_5_trends:
        trend_data = filtered_trends_2021_2025[filtered_trends_2021_2025['AI_Trend'] == trend]

        if not trend_data.empty and len(trend_data) >= 2:
            X = trend_data['Year'].values.reshape(-1, 1)
            y = trend_data['Model_Count'].values
            # st.write(f"ุงูุจูุงูุงุช ูู {trend} (X): {X}")
            # st.write(f"ุงูุจูุงูุงุช ูู {trend} (y): {y}")

            model = LinearRegression()
            model.fit(X, y)
            trend_models[trend] = model
            prediction_2026 = model.predict([[2026]])
            trend_predictions_2026[trend] = max(0, int(round(prediction_2026[0])))
        else:
            st.write(f"ุจูุงูุงุช ุบูุฑ ูุงููุฉ ููุงุชุฌุงู: {trend} ูู ุงูุฃุนูุงู 2021-2025 ูุชุฏุฑูุจ ุงููููุฐุฌ. ูุฏ ุชุญุชุงุฌ ุฅูู ุงููุฒูุฏ ูู ุงูููุงุท.")
            trend_predictions_2026[trend] = 0

    st.write("ุชู ุชุฏุฑูุจ ููุงุฐุฌ ุงูุงูุญุฏุงุฑ ุงูุฎุทู ูุฃูู 5 ุงุชุฌุงูุงุช.")
    st.write("ุนุฏุฏ ุงูููุงุฐุฌ ุงููุชููุนุฉ ูุนุงู 2026:")
    for trend, count in trend_predictions_2026.items():
        st.write(f"{trend}: {count}")

    predictions_df = pd.DataFrame(list(trend_predictions_2026.items()), columns=['AI_Trend', 'Predicted_Model_Count_2026'])
    predictions_df = predictions_df.sort_values(by='Predicted_Model_Count_2026', ascending=False)

    sns.set(style="whitegrid")
    fig_pred_bar, ax_pred_bar = plt.subplots(figsize=(10, 6))
    sns.barplot(data=predictions_df, x='Predicted_Model_Count_2026', y='AI_Trend', palette='viridis', ax=ax_pred_bar)
    ax_pred_bar.set_title('ุนุฏุฏ ุงูููุงุฐุฌ ุงููุชููุน ูุฃูู 5 ุงุชุฌุงูุงุช ููุฐูุงุก ุงูุงุตุทูุงุนู ูู ุนุงู 2026')
    ax_pred_bar.set_xlabel('ุนุฏุฏ ุงูููุงุฐุฌ ุงููุชููุน')
    ax_pred_bar.set_ylabel('ุงุชุฌุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู')
    plt.tight_layout()
    st.pyplot(fig_pred_bar)
    plt.close(fig_pred_bar)
else:
    st.warning("ูุง ูููู ุฅุฌุฑุงุก ุชุญููู ุงูุงูุญุฏุงุฑ. ูู ูุชู ุชุญุฏูุฏ ุฃูู 5 ุงุชุฌุงูุงุช ููุฐูุงุก ุงูุงุตุทูุงุนู ุฃู ุฃููุง ูุงุฑุบุฉุ ุฃู ุจูุงูุงุช ุงูุงุชุฌุงูุงุช ุงูุณูููุฉ ุบูุฑ ูุชุงุญุฉ.")


# ุฃูู ููุธูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุญุณุจ ุนุฏุฏ ุงูููุงุฐุฌ (ุจูุงุณุทุฉ Basmaleh)
st.subheader("ุฃูู ููุธูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุญุณุจ ุนุฏุฏ ุงูููุงุฐุฌ")
if 'Organization' in df.columns and not df.empty:
    org_counts = df['Organization'].value_counts().reset_index()
    org_counts.columns = ['Organization', 'Model_Count']

    st.write("ุฃูุถู ููุชุฌู ุงูููุงุฐุฌ:")
    st.dataframe(org_counts.head(10))

    fig_org_top10, ax_org_top10 = plt.subplots(figsize=(12, 6))
    sns.barplot(data=org_counts.head(10), x='Model_Count', y='Organization', palette='viridis', ax=ax_org_top10)
    ax_org_top10.set_title('ุฃูู 10 ููุธูุงุช ุฐูุงุก ุงุตุทูุงุนู ุญุณุจ ุนุฏุฏ ุงูููุงุฐุฌ')
    ax_org_top10.set_xlabel('ุนุฏุฏ ุงูููุงุฐุฌ')
    ax_org_top10.set_ylabel('ุงูููุธูุฉ')
    plt.tight_layout()
    st.pyplot(fig_org_top10)
    plt.close(fig_org_top10)
else:
    st.warning("ูุง ูููู ุนุฑุถ ุฃูู ุงูููุธูุงุช. ุนููุฏ 'Organization' ููููุฏ ุฃู DataFrame ูุงุฑุบ.")
'''

# ุงุณุชุฎุฏู code_editor ูุชุฌุฑุจุฉ ุชุญุฑูุฑ ุฃูุถู (ุงุฎุชูุงุฑู)
try:
    from code_editor import code_editor
    # ููููู ุถุจุท ุงููููุฉ ุงูุฃูููุฉ ูู user_code ููุง
    response_dict = code_editor(cody, lang="python", height=800,
                                editor_props={"theme": "dracula"}) # ููููู ุชุบููุฑ ุงููุธูุฑ
    # ุชุฃูุฏ ูู ุฃู user_code ูุง ูุตุจุญ None ุฅุฐุง ูู ููู ููุงู ุงุณุชุฌุงุจุฉ ูู code_editor
    user_code_from_editor = response_dict['text'] if response_dict and 'text' in response_dict else cody
except ImportError:
    st.warning("`streamlit-code-editor` ุบูุฑ ูุซุจุช. ุงูุฑุฌุงุก ุชุซุจูุชู (pip install streamlit-code-editor) ููุญุตูู ุนูู ุชุฌุฑุจุฉ ูุญุฑุฑ ุฃูุถูุ ุฃู ุณูุชู ุงุณุชุฎุฏุงู `st.text_area`.")
    user_code_from_editor = st.text_area("โ๏ธ ุนุฏูู ุงูููุฏ ููุง:", cody, height=800)


# --- ุฒุฑ ุงูุชุดุบูู ---
if st.button("ุชุดุบูู ุงูุชุญููู"):
    # ุฅุฐุง ูู ููู ุงููุณุชุฎุฏู ุจุชุบููุฑ ุงูููุฏุ ุชุฃูุฏ ูู ุงุณุชุฎุฏุงู ุงูููุฏ ุงูุงูุชุฑุงุถู
    # ูุฐุง ูุญู ูุดููุฉ "ูุฑุฌู ุฅุฏุฎุงู ููุฏ Python ููุชูููุฐ" ุนูุฏ ุงูุชุดุบูู ุงูุฃูู
    # ูุฃู user_code_from_editor ูุฏ ูููู ูุงุฑุบูุง ูู ุงูุจุฏุงูุฉ
    if not user_code_from_editor.strip(): # ุงูุชุญูู ููุง ุฅุฐุง ูุงูุช ุงูุณูุณูุฉ ูุงุฑุบุฉ ุจุนุฏ ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุจูุถุงุก
        final_user_code = cody # ุงุณุชุฎุฏู ุงูููุฏ ุงูุงูุชุฑุงุถู
    else:
        final_user_code = user_code_from_editor # ุงุณุชุฎุฏู ุงูููุฏ ุงูุฐู ุฃุฏุฎูู ุงููุณุชุฎุฏู

    if df is not None: # ุชุฃูุฏ ูู ุชุญููู df
        try:
            st.empty() # ูุณุญ ุงููุฎุฑุฌุงุช ุงูุณุงุจูุฉ

            # ุฅูุดุงุก ูุณุฎุฉ ูู DataFrame ูุชุฌูุจ ุชุนุฏูู df ุงูุฃุตูู ุจูุงุณุทุฉ ููุฏ ุงููุณุชุฎุฏู
            df_for_exec = df.copy()

            # ุชุญุฏูุฏ ุงูุจูุฆุฉ ุงูุชู ุณูุชู ูููุง ุชูููุฐ ููุฏ ุงููุณุชุฎุฏู
            exec_globals = {
                'st': st, 'pd': pd, 'np': np, 'plt': plt, 'sns': sns,
                'df': df_for_exec, # ุชูุฑูุฑ ุงููุณุฎุฉ ุงููุนุฏูุฉ
                'StandardScaler': StandardScaler, 'OneHotEncoder': OneHotEncoder, 'LabelEncoder': LabelEncoder,
                'ColumnTransformer': ColumnTransformer, 'Pipeline': Pipeline,
                'SimpleImputer': SimpleImputer, 'KMeans': KMeans, 'PCA': PCA,
                'train_test_split': train_test_split, 'RandomForestClassifier': RandomForestClassifier,
                'accuracy_score': accuracy_score, 'precision_score': precision_score,
                'recall_score': recall_score, 'f1_score': f1_score, 'confusion_matrix': confusion_matrix,
                'classification_report': classification_report,
                'LinearRegression': LinearRegression, 'KNeighborsClassifier': KNeighborsClassifier
            }
            exec(final_user_code, exec_globals) # ุชูููุฐ ุงูููุฏ

            st.success("ุชู ุชูููุฐ ุงูููุฏ ุจูุฌุงุญ!")
            st.write("---")
            st.write("ุงูุชูู ุงูุชุญููู. ููููู ุชุนุฏูู ุงูููุฏ ุฃุนูุงู ูุฅุนุงุฏุฉ ุงูุชุดุบูู.")

        except Exception as e:
            st.error(f"ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุชูููุฐ ุงูููุฏ: {e}")
            st.exception(e) # ูุนุฑุถ ุชุชุจุน ุงูุฎุทุฃ ุงููุงูู
    else:
        st.warning("ุงูุฑุฌุงุก ุงูุชุฃูุฏ ูู ุชุญููู ููู ุงูุจูุงูุงุช ุฃููุงู.")